{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanujsharma/opt/anaconda3/lib/python3.9/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/ramanujsharma/opt/anaconda3/lib/python3.9/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010 = pd.read_excel('online_retail.xlsx', sheet_name = 0)\n",
    "df_2011 = pd.read_excel('online_retail.xlsx', sheet_name = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Market Basket Analysis with Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for Apriori\n",
    "transactions_2010 = df_2010.groupby('Invoice')['Description'].apply(list)\n",
    "transactions_2011 = df_2011.groupby('Invoice')['Description'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all items to strings\n",
    "transactions_2010 = transactions_2010.apply(lambda items: [str(item) for item in items])\n",
    "transactions_2011 = transactions_2011.apply(lambda items: [str(item) for item in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine transactions\n",
    "transactions = pd.concat([transactions_2010, transactions_2011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction encoding\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions).transform(transactions)\n",
    "df_te = pd.DataFrame(te_data, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Apriori\n",
    "frequent_itemsets = apriori(df_te, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(72 SWEETHEART FAIRY CAKE CASES)</td>\n",
       "      <td>(60 TEATIME FAIRY CAKE CASES)</td>\n",
       "      <td>0.027286</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.503014</td>\n",
       "      <td>12.636785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>1.932035</td>\n",
       "      <td>0.946698</td>\n",
       "      <td>0.257192</td>\n",
       "      <td>0.482411</td>\n",
       "      <td>0.423913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(60 TEATIME FAIRY CAKE CASES)</td>\n",
       "      <td>(72 SWEETHEART FAIRY CAKE CASES)</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.027286</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.344812</td>\n",
       "      <td>12.636785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>1.484632</td>\n",
       "      <td>0.959041</td>\n",
       "      <td>0.257192</td>\n",
       "      <td>0.326433</td>\n",
       "      <td>0.423913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(PACK OF 60 DINOSAUR CAKE CASES)</td>\n",
       "      <td>(60 TEATIME FAIRY CAKE CASES)</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>12.941704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>1.980401</td>\n",
       "      <td>0.945541</td>\n",
       "      <td>0.241306</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>0.413682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(60 TEATIME FAIRY CAKE CASES)</td>\n",
       "      <td>(PACK OF 60 DINOSAUR CAKE CASES)</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.312213</td>\n",
       "      <td>12.941704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>1.418863</td>\n",
       "      <td>0.960983</td>\n",
       "      <td>0.241306</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.413682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(PACK OF 60 PINK PAISLEY CAKE CASES)</td>\n",
       "      <td>(60 TEATIME FAIRY CAKE CASES)</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.466339</td>\n",
       "      <td>11.715431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015864</td>\n",
       "      <td>1.799259</td>\n",
       "      <td>0.949974</td>\n",
       "      <td>0.290748</td>\n",
       "      <td>0.444216</td>\n",
       "      <td>0.451030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            antecedents                       consequents  \\\n",
       "0      (72 SWEETHEART FAIRY CAKE CASES)     (60 TEATIME FAIRY CAKE CASES)   \n",
       "1         (60 TEATIME FAIRY CAKE CASES)  (72 SWEETHEART FAIRY CAKE CASES)   \n",
       "2      (PACK OF 60 DINOSAUR CAKE CASES)     (60 TEATIME FAIRY CAKE CASES)   \n",
       "3         (60 TEATIME FAIRY CAKE CASES)  (PACK OF 60 DINOSAUR CAKE CASES)   \n",
       "4  (PACK OF 60 PINK PAISLEY CAKE CASES)     (60 TEATIME FAIRY CAKE CASES)   \n",
       "\n",
       "   antecedent support  consequent support   support  confidence       lift  \\\n",
       "0            0.027286            0.039806  0.013725    0.503014  12.636785   \n",
       "1            0.039806            0.027286  0.013725    0.344812  12.636785   \n",
       "2            0.024125            0.039806  0.012428    0.515152  12.941704   \n",
       "3            0.039806            0.024125  0.012428    0.312213  12.941704   \n",
       "4            0.037192            0.039806  0.017344    0.466339  11.715431   \n",
       "\n",
       "   representativity  leverage  conviction  zhangs_metric   jaccard  certainty  \\\n",
       "0               1.0  0.012639    1.932035       0.946698  0.257192   0.482411   \n",
       "1               1.0  0.012639    1.484632       0.959041  0.257192   0.326433   \n",
       "2               1.0  0.011468    1.980401       0.945541  0.241306   0.495052   \n",
       "3               1.0  0.011468    1.418863       0.960983  0.241306   0.295210   \n",
       "4               1.0  0.015864    1.799259       0.949974  0.290748   0.444216   \n",
       "\n",
       "   kulczynski  \n",
       "0    0.423913  \n",
       "1    0.423913  \n",
       "2    0.413682  \n",
       "3    0.413682  \n",
       "4    0.451030  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overview\n",
    "This analysis uses the Apriori algorithm to extract association rules from the transaction dataset. The goal is to identify relationships between different products that are frequently bought together.\n",
    "\n",
    "### Association Rules\n",
    "\n",
    "#### Key Findings\n",
    "1. **Rule 1**: Buying *60 Teatime Fairy Cake Cases* often leads to buying *72 Sweetheart Fairy Cake Cases*. \n",
    "   - **Support**: 0.0137\n",
    "   - **Confidence**: 34.48%\n",
    "   - **Lift**: 12.64\n",
    "\n",
    "2. **Rule 2**: Buying *72 Sweetheart Fairy Cake Cases* is associated with the purchase of *60 Teatime Fairy Cake Cases*.\n",
    "   - **Support**: 0.0137\n",
    "   - **Confidence**: 50.30%\n",
    "   - **Lift**: 12.64\n",
    "\n",
    "3. **Rule 3**: *60 Teatime Fairy Cake Cases* and *Pack of 60 Dinosaur Cake Cases* are often bought together.\n",
    "   - **Support**: 0.0124\n",
    "   - **Confidence**: 31.22%\n",
    "   - **Lift**: 12.94\n",
    "\n",
    "#### Interpretation\n",
    "- **Support** indicates how frequently the itemset appears in the dataset.\n",
    "- **Confidence** measures the reliability of the rule.\n",
    "- **Lift** indicates how much more likely the items are bought together compared to being bought independently.\n",
    "\n",
    "### Conclusion\n",
    "Understanding these relationships allows businesses to make informed decisions about product placement, cross-promotions, and inventory management to enhance sales strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Price Elasticity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate price elasticity\n",
    "def calculate_elasticity(df):\n",
    "    df['Revenue'] = df['Quantity'] * df['Price']\n",
    "    df = df[df['Quantity'] != 0]  # Avoid division by zero\n",
    "    df['Elasticity'] = (df['Quantity'].pct_change() / df['Price'].pct_change()).replace([np.inf, -np.inf], np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for 2010 and 2011\n",
    "elasticity_2010 = calculate_elasticity(df_2010)\n",
    "elasticity_2011 = calculate_elasticity(df_2011)\n",
    "\n",
    "elastic_products_2010 = elasticity_2010[['Description', 'Elasticity']].dropna().groupby('Description').mean()\n",
    "elastic_products_2011 = elasticity_2011[['Description', 'Elasticity']].dropna().groupby('Description').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Elastic Products 2010:\n",
      "                         Elasticity\n",
      "Description                        \n",
      "ebay sales              2837.944444\n",
      "mouldy                  1001.000000\n",
      "Rusty                    852.000000\n",
      "Given away               734.333333\n",
      "wet/smashed/unsellable   701.000000\n",
      "Top Elastic Products 2011:\n",
      "                               Elasticity\n",
      "Description                              \n",
      "Thrown away-rusty             2377.000000\n",
      "Unsaleable, destroyed.        1672.000000\n",
      "Printing smudges/thrown away  1510.666667\n",
      "lost??                        1132.000000\n",
      "mouldy, thrown away.           867.666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Elastic Products 2010:\")\n",
    "print(elastic_products_2010.sort_values(by='Elasticity', ascending=False).head())\n",
    "print(\"Top Elastic Products 2011:\")\n",
    "print(elastic_products_2011.sort_values(by='Elasticity', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This analysis examines the price elasticity of products for 2010 and 2011. Elasticity measures how sensitive the quantity demanded is to a change in price. High elasticity indicates significant consumer response to price changes, which is crucial for pricing strategy.\n",
    "\n",
    "### Top Elastic Products\n",
    "\n",
    "#### 2010\n",
    "1. **ebay sales**\n",
    "   - **Elasticity**: 2837.94\n",
    "2. **mouldy**\n",
    "   - **Elasticity**: 1001.00\n",
    "3. **Rusty**\n",
    "   - **Elasticity**: 852.00\n",
    "4. **Given away**\n",
    "   - **Elasticity**: 734.33\n",
    "5. **wet/smashed/unsellable**\n",
    "   - **Elasticity**: 701.00\n",
    "\n",
    "#### 2011\n",
    "1. **Thrown away—rusty**\n",
    "   - **Elasticity**: 2377.00\n",
    "2. **Unsaleable, destroyed**\n",
    "   - **Elasticity**: 1672.00\n",
    "3. **Printing smudges/thrown away**\n",
    "   - **Elasticity**: 1510.67\n",
    "4. **lost??**\n",
    "   - **Elasticity**: 1132.00\n",
    "5. **mouldy, thrown away**\n",
    "   - **Elasticity**: 867.67\n",
    "\n",
    "### Interpretation\n",
    "Products with high elasticity show a strong demand response to price changes. This insight helps in:\n",
    "\n",
    "- **Pricing Strategy**: Adjusting prices for elastic products can significantly impact sales volumes.\n",
    "- **Marketing Focus**: Promotional strategies can target these products to optimize sales.\n",
    "\n",
    "### Conclusion\n",
    "Identifying highly elastic products enables businesses to make data-driven pricing decisions, optimizing revenue while addressing consumer sensitivity to price changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
